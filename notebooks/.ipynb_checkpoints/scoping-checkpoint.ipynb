{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371b3984-748e-4073-a415-e994e746af0c",
   "metadata": {},
   "source": [
    "#### Import Env and check first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00436159-841f-4663-801b-1da77b323833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a751ccd-dcd8-4841-9445-59a0275ebf9c",
   "metadata": {},
   "source": [
    "#### Works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a008ece0-a36c-4150-8bcc-714cd2fd2a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "These are the messages that have been exchanged so far from the user asking for the report:\n",
      "<Messages>\n",
      "{messages}\n",
      "</Messages>\n",
      "\n",
      "Today's date is {date}.\n",
      "\n",
      "Assess whether you need to ask a clarifying question, or if the user has already provided enough information for you to start research.\n",
      "IMPORTANT: If you can see in the messages history that you have already asked a clarifying question, you almost always do not need to ask another one. Only ask another question if ABSOLUTELY NECESSARY.\n",
      "\n",
      "If there are acronyms, abbreviations, or unknown terms, ask the user to clarify.\n",
      "If you need to ask a question, follow these guidelines:\n",
      "- Be concise while gathering all necessary information\n",
      "- Make sure to gather all the information needed to carry out the research task in a concise, well-structured manner.\n",
      "- Use bullet points or numbered lists if appropriate for clarity. Make sure that this uses markdown formatting and will be rendered correctly if the string output is passed to a markdown renderer.\n",
      "- Don't ask for unnecessary information, or information that the user has already provided. If you can see that the user has already provided the information, do not ask for it again.\n",
      "\n",
      "Respond in valid JSON format with these exact keys:\n",
      "\"need_clarification\": boolean,\n",
      "\"question\": \"<question to ask the user to clarify the report scope>\",\n",
      "\"verification\": \"<verification message that we will start research>\"\n",
      "\n",
      "If you need to ask a clarifying question, return:\n",
      "\"need_clarification\": true,\n",
      "\"question\": \"<your clarifying question>\",\n",
      "\"verification\": \"\"\n",
      "\n",
      "If you do not need to ask a clarifying question, return:\n",
      "\"need_clarification\": false,\n",
      "\"question\": \"\",\n",
      "\"verification\": \"<acknowledgement message that you will now start research based on the provided information>\"\n",
      "\n",
      "For the verification message when no clarification is needed:\n",
      "- Acknowledge that you have sufficient information to proceed\n",
      "- Briefly summarize the key aspects of what you understand from their request\n",
      "- Confirm that you will now begin the research process\n",
      "- Keep the message concise and professional\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deep_research.prompts import clarify_with_user_instructions\n",
    "print(clarify_with_user_instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3540ad77-76d8-4872-ac8d-a9ecb1804ffe",
   "metadata": {},
   "source": [
    "## Build State for Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfdbff8-a5d3-42f2-a3fd-7422fdeaf77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/deep_research/state_scope.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/deep_research/state_scope.py\n",
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from typing_extensions import Optional, Annotated, Sequence\n",
    "import operator\n",
    "from langgraph.graph.message import BaseMessage,add_messages\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class AgentInputState(MessagesState):\n",
    "    \"\"\"Input State for the Agent. Only contains the user's input message\"\"\"\n",
    "    pass\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"State of the Agent while Agent researches on the topic\"\"\"\n",
    "    research_brief : Optional[str]\n",
    "    supervisor_messages : Annotated[Sequence[BaseMessage], add_messages]\n",
    "    raw_notes: Annotated[list[str], operator.add] = []\n",
    "    notes: Annotated[list[str], operator.add] = []\n",
    "    final_report : str\n",
    "\n",
    "class ClarifyWithUser(BaseModel):\n",
    "    \"\"\"Clarification Schema for clarifying before starting the researching\"\"\"\n",
    "    need_clarification : bool = Field(\n",
    "        description=\"Wether the user needs to be asked for clarifying question\"\n",
    "    )\n",
    "\n",
    "    question : str = Field(\n",
    "        description= \"A question to ask the user to clarify the research scope\"\n",
    "    )\n",
    "\n",
    "    verification : str = Field(\n",
    "        description=\"Verify message that we will start research, after the user has provided the necessary information\"\n",
    "    )\n",
    "\n",
    "class ResearchQuestion(BaseModel):\n",
    "    \"\"\"The Actual Search question to be provided for research\"\"\"\n",
    "    research_brief : str = Field(\n",
    "        description=\"A research question that will be used to guide the research\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52726dd3-0166-47f8-a4c8-14c80c4f1b75",
   "metadata": {},
   "source": [
    "Agent State defined now continue with the clarification node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15880a51-40c4-4f3a-8cec-2501f3dce349",
   "metadata": {},
   "source": [
    "#### Now create a open router wrapper for creating our chat models, this will help us explore opensource models and other paid models from openrouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b0e0479-28dc-4e80-847e-253aaa27efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/deep_research/openrouter.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/deep_research/openrouter.py\n",
    "\"\"\"\n",
    "Module to init chat models from openrouter and use various opensource\n",
    "and free models for deep research\n",
    "\"\"\"\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import Optional\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def init_chat_model(model: str, api_key: Optional[str], temperature: str=0, base_url: str = 'https://openrouter.ai/api/v1'):\n",
    "    \"\"\"Chat model initialization similar to langchain init_chat_model, but specific to openrouter\"\"\"\n",
    "    open_router_key = api_key\n",
    "    if not open_router_key and not os.getenv('OPENROUTER_API_KEY'):\n",
    "        raise ValueError('API Key not provided, either provide OPENROUTER_API_KEY as evironment variable or provide in the function')        \n",
    "    return ChatOpenAI(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        api_key = open_router_key if open_router_key else os.getenv('OPENROUTER_API_KEY'),\n",
    "        base_url= base_url\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fe342-dbfc-42df-a3dd-6742ce028cc5",
   "metadata": {},
   "source": [
    "### Making the clarification node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c8227c8-d558-4885-ab1f-6cc1786aa00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/deep_research/scope_research.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/deep_research/scope_research.py\n",
    "\n",
    "\"\"\"\n",
    "Contains Nodes and the graph flow to clarify with user and finally have determine the proper research scope\n",
    "\"\"\"\n",
    "\n",
    "from deep_research.state_scope import AgentState, ClarifyWithUser, ResearchQuestion, AgentInputState\n",
    "from typing import Literal\n",
    "from langgraph.types import Command\n",
    "import os\n",
    "from deep_research.prompts import clarify_with_user_instructions, transform_messages_into_research_topic_prompt\n",
    "from langchain_core.messages import HumanMessage, get_buffer_string, AIMessage\n",
    "from datetime import datetime\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from dotenv import load_dotenv\n",
    "from deep_research.openrouter import init_chat_model\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def get_today_str():\n",
    "    \"\"\"return todays date in windows, different method for other os\"\"\"\n",
    "    return datetime.now().strftime(\"%Y -%m -%d\")\n",
    "\n",
    "model = init_chat_model(model = \"x-ai/grok-4-fast:free\", api_key=os.getenv('OPENAI_API_KEY'), temperature=0)\n",
    "\n",
    "def clarify_with_user(state : AgentState)-> Command[Literal[\"write_research_brief\", \"__end__\"]]:\n",
    "    \"\"\"\n",
    "    Determine if the user's request contains sufficient information to proceed with research.\n",
    "    \n",
    "    Uses structured output to make deterministic decisions and avoid hallucination.\n",
    "    Routes to either research brief generation or ends with a clarification question.\n",
    "    \"\"\"\n",
    "\n",
    "    structured_model = model.with_structured_output(ClarifyWithUser)\n",
    "    response = structured_model.invoke([\n",
    "        HumanMessage(content = clarify_with_user_instructions.format(\n",
    "            messages = get_buffer_string(messages=state['messages']),\n",
    "            date = get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    if response.need_clarification:\n",
    "        return Command(\n",
    "            goto=END,\n",
    "            update={\"messages\" : AIMessage(content=response.question)}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"write_research_brief\",\n",
    "            update={\"messages\" : AIMessage(content=response.verification)}\n",
    "        )\n",
    "\n",
    "def write_research_brief(state : AgentState):\n",
    "    \"\"\"\n",
    "    Transform the conversation history into a comprehensive research brief.\n",
    "    \n",
    "    Uses structured output to ensure the brief follows the required format\n",
    "    and contains all necessary details for effective research.\n",
    "    \"\"\"\n",
    "    structured_model = model.with_structured_output(ResearchQuestion)\n",
    "\n",
    "    response = structured_model.invoke([\n",
    "        HumanMessage(content=transform_messages_into_research_topic_prompt.format(\n",
    "            messages=get_buffer_string(messages=state.get('messages',[])),\n",
    "            date=get_today_str()\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    return {\n",
    "        \"research_brief\" : response.research_brief,\n",
    "        \"supervisor_brief\" : response.research_brief\n",
    "    }\n",
    "\n",
    "\n",
    "deep_research_builder = StateGraph(AgentState, input_schema = AgentInputState)\n",
    "\n",
    "deep_research_builder.add_node('clarify_with_user', clarify_with_user)\n",
    "deep_research_builder.add_node('write_research_brief', write_research_brief)\n",
    "\n",
    "deep_research_builder.add_edge(START, 'clarify_with_user')\n",
    "deep_research_builder.add_edge('write_research_brief', END)\n",
    "\n",
    "scope_research = deep_research_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285e7faa-bab2-4bac-ba10-4d021fdeadbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "# print(scope_research.get_graph(xray=True).draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aaab23-7818-48f3-8d53-fda9f32f14b9",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce1cf9ed-bfa1-4f52-a872-eb437a3cf244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_research.scope_research import deep_research_builder\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "scope = deep_research_builder.compile(checkpointer = checkpointer)\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "result = scope.invoke({\"messages\": [HumanMessage(content=\"I want to research on some attraction games\")]}, config=thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9dd1401-210c-40a4-82b2-6bb1d0ba4f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='I want to research on some attraction games', additional_kwargs={}, response_metadata={}, id='49efe751-b1a2-4af9-86dc-5c891c861789'), AIMessage(content=\"Could you please clarify what you mean by 'attraction games'? For example, are you referring to amusement park attractions, video games with attraction themes, social or dating games, or something else? Also, what specific aspects would you like to research, such as history, popular examples, or trends?\", additional_kwargs={}, response_metadata={}, id='ddde7572-bf89-448f-b6e9-bec84592fe09')], 'supervisor_messages': [], 'raw_notes': [], 'notes': []}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cfde38-902e-4c52-8892-81d1ef66cb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
